# ğŸ˜Š Facial Emotion Detection Web Application

A machine learning web application that detects emotions from facial images using a Convolutional Neural Network (CNN) trained on the FER2013 dataset.

## ğŸ“‹ Features

- **Emotion Detection**: Classifies faces into 7 emotions (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral)
- **Web Interface**: Simple HTML form for user input and image upload
- **Database Storage**: Saves user information and images to SQLite database
- **Personalized Responses**: Returns emotion-specific messages
- **Face Detection**: Uses OpenCV's Haar Cascade for face detection

## ğŸ“ Project Structure

```
FACE_DETECTION/
â”‚
â”œâ”€â”€ app.py                   # Flask web application
â”œâ”€â”€ model_training.py        # Model training script
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ database.db             # SQLite database (created on first run)
â”œâ”€â”€ face_emotionModel.h5    # Trained model (created after training)
â”œâ”€â”€ link_web_app.txt        # Deployment URL
â”œâ”€â”€ .gitignore              # Git ignore file
â”œâ”€â”€ README.md               # This file
â”‚
â””â”€â”€ templates/
     â””â”€â”€ index.html         # Frontend interface
```

## ğŸš€ Setup Instructions

### Prerequisites

- Python 3.8 or higher
- FER2013 dataset downloaded

### Installation

1. Navigate to the project directory:

```bash
cd FACE_DETECTION
```

2. Create a virtual environment (recommended):

```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

### Training the Model

1. Ensure the FER2013 dataset is in the correct location
2. Run the training script:

```bash
python model_training.py
```

3. Wait for training to complete (may take 1-3 hours depending on hardware)
4. The trained model will be saved as `face_emotionModel.h5`

### Running the Application

1. Start the Flask server:

```bash
python app.py
```

2. Open your browser and go to:

```
http://localhost:5000
```

3. Fill in the form and upload an image to test the emotion detection!

## ğŸ§ª Testing

Test the application with various facial images showing different emotions. The model works best with:

- Clear, front-facing photos
- Good lighting
- Single person in the image
- Visible facial features

## ğŸ“Š Model Details

- **Architecture**: CNN with 4 convolutional blocks
- **Input**: 48x48 grayscale images
- **Output**: 7 emotion classes
- **Dataset**: FER2013 (35,887 images)
- **Framework**: TensorFlow/Keras

## ğŸŒ Deployment

This application can be deployed to Render or similar platforms. Full deployment instructions will be provided in the guide.

## ğŸ“ Notes

- The model's accuracy depends on image quality and facial visibility
- First-time training may take significant time
- Database and uploads folders are created automatically


## ğŸ“„ License

This project is for educational purposes.
